{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import ResNetFeat\n",
    "import yaml\n",
    "import data\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import h5py\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('base_classes.json') as f:\n",
    "    base_classes=json.load(f)\n",
    "\n",
    "with open('novel_classes.json') as f:\n",
    "    novel_classes=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg='train_save_data.yaml'\n",
    "val_cfg='val_save_data.yaml'\n",
    "modelfile='checkpoints/ResNet10_sgm/19.tar'\n",
    "model='ResNet10'\n",
    "num_classes=10\n",
    "batch_size=16\n",
    "maxiters=1000\n",
    "lr=0.1\n",
    "momentum=0.9\n",
    "wd=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name, num_classes):\n",
    "    model_dict = dict(ResNet10 = ResNetFeat.ResNet10,\n",
    "                ResNet18 = ResNetFeat.ResNet18,\n",
    "                ResNet34 = ResNetFeat.ResNet34,\n",
    "                ResNet50 = ResNetFeat.ResNet50,\n",
    "                ResNet101 = ResNetFeat.ResNet101)\n",
    "    return model_dict[model_name](num_classes, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(model,data_loader):\n",
    "    \n",
    "    feature_set=[]\n",
    "    label_set=[]\n",
    "    for i, (x,y) in enumerate(data_loader):\n",
    "        \n",
    "        \n",
    "        # ignoriang the data that belong to base class\n",
    "        index=0\n",
    "        while True:\n",
    "            if(y[index] not in novel_classes):\n",
    "                y=torch.cat([y[0:index], y[index+1:]])\n",
    "                x=torch.cat([x[0:index], x[index+1:]])\n",
    "                index-=1\n",
    "            index+=1\n",
    "\n",
    "            if(len(y)==index):\n",
    "                break\n",
    "\n",
    "        if(len(y)==0):\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        if i%10 == 0:\n",
    "            print('{:d}/{:d}'.format(i, len(data_loader)))\n",
    "        x = x.cuda()\n",
    "        x_var = Variable(x)\n",
    "        \n",
    "        scores, feats = model(x_var)\n",
    "        feature_set.extend(feats.data.cpu().numpy())\n",
    "        label_set.extend(y.cpu().numpy())\n",
    "        \n",
    "    return (np.array(feature_set),np.array(label_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rupak/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/transforms/transforms.py:188: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    with open(cfg,'r') as f:\n",
    "        data_params = yaml.load(f)\n",
    "\n",
    "    data_loader = data.get_data_loader(data_params)\n",
    "    \n",
    "    with open(val_cfg,'r') as f:\n",
    "        val_params = yaml.load(f)\n",
    "    val_loader = data.get_data_loader(val_params)\n",
    "\n",
    "    model = get_model(model, num_classes)\n",
    "    model = model.cuda()\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    tmp = torch.load(modelfile)\n",
    "    if ('module.classifier.bias' not in model.state_dict().keys()) and ('module.classifier.bias' in tmp['state'].keys()):\n",
    "        tmp['state'].pop('module.classifier.bias')\n",
    "    \n",
    "    model.load_state_dict(tmp['state'])\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3130/3141\n",
      "3140/3141\n",
      "630/1250\n",
      "640/1250\n",
      "650/1250\n",
      "660/1250\n",
      "670/1250\n",
      "680/1250\n",
      "690/1250\n",
      "700/1250\n",
      "710/1250\n",
      "720/1250\n",
      "730/1250\n",
      "740/1250\n",
      "750/1250\n",
      "760/1250\n",
      "770/1250\n",
      "780/1250\n",
      "790/1250\n",
      "800/1250\n",
      "810/1250\n",
      "820/1250\n",
      "830/1250\n",
      "840/1250\n",
      "850/1250\n",
      "860/1250\n",
      "870/1250\n",
      "880/1250\n",
      "890/1250\n",
      "900/1250\n",
      "910/1250\n",
      "920/1250\n",
      "930/1250\n",
      "940/1250\n",
      "950/1250\n",
      "960/1250\n",
      "970/1250\n",
      "980/1250\n",
      "990/1250\n",
      "1000/1250\n",
      "1010/1250\n",
      "1020/1250\n",
      "1030/1250\n",
      "1040/1250\n",
      "1050/1250\n",
      "1060/1250\n",
      "1070/1250\n",
      "1080/1250\n",
      "1090/1250\n",
      "1100/1250\n",
      "1110/1250\n",
      "1120/1250\n",
      "1130/1250\n",
      "1140/1250\n",
      "1150/1250\n",
      "1160/1250\n",
      "1170/1250\n",
      "1180/1250\n",
      "1190/1250\n",
      "1200/1250\n",
      "1210/1250\n",
      "1220/1250\n",
      "1230/1250\n",
      "1240/1250\n"
     ]
    }
   ],
   "source": [
    "feature_set,label_set=get_features(model,data_loader)\n",
    "val_feature_set,val_label_set = get_features(model,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(features,labels, num_classes, lr, momentum, wd, batchsize=1000, maxiters=1000):\n",
    "    featdim = features.shape[1]\n",
    "    model = nn.Linear(featdim, num_classes)\n",
    "    model = model.cuda()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr, momentum=momentum, dampening=momentum, weight_decay=wd)\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    loss_function = loss_function.cuda()\n",
    "    \n",
    "    for i in range(maxiters):\n",
    "        idx=i%len(labels)\n",
    "        (x,y) = torch.tensor(np.array([features[idx]])),torch.tensor(np.array([labels[idx]]))\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = Variable(x.cuda())\n",
    "        y = Variable(y.cuda())\n",
    "        scores = model(x)\n",
    "        loss = loss_function(scores,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i%100==0):\n",
    "            print('{:d}: {:f}'.format(i, loss.data[0]))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rupak/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 2.220948\n",
      "100: 5.572062\n",
      "200: 2.830403\n",
      "300: 1.657817\n",
      "400: 3.138130\n",
      "500: 0.907409\n",
      "600: 0.276873\n",
      "700: 0.697453\n",
      "800: 0.347649\n",
      "900: 2.507155\n"
     ]
    }
   ],
   "source": [
    "one_shot_model = training_loop(feature_set,label_set, num_classes, lr, momentum, wd, batch_size, maxiters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_loop(one_shot_model,val_features,val_labels):\n",
    "    one_shot_model=one_shot_model.eval()\n",
    "    \n",
    "    total=0\n",
    "    for i in range(100):\n",
    "        idx=i%len(val_labels)\n",
    "        (x,y) = torch.tensor(np.array([val_features[idx]])),torch.tensor(np.array([val_labels[idx]]))\n",
    "        \n",
    "        x = Variable(x.cuda())\n",
    "        scores = one_shot_model(x)\n",
    "        x=np.argmax(scores.data)==y[0]\n",
    "        total+=x\n",
    "    total=total.numpy()\n",
    "    print('mean accuracy : {}%'.format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy : 21%\n"
     ]
    }
   ],
   "source": [
    "testing_loop(one_shot_model,val_feature_set,val_label_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
