{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import ResNetFeat\n",
    "import yaml\n",
    "import data\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import h5py\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('base_classes.json') as f:\n",
    "    base_classes=json.load(f)\n",
    "\n",
    "with open('novel_classes.json') as f:\n",
    "    novel_classes=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg='train_save_data.yaml'\n",
    "modelfile='checkpoints/ResNet10_sgm/19.tar'\n",
    "model='ResNet10'\n",
    "num_classes=10\n",
    "batch_size=16\n",
    "maxiters=1000\n",
    "lr=0.1\n",
    "momentum=0.9\n",
    "wd=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name, num_classes):\n",
    "    model_dict = dict(ResNet10 = ResNetFeat.ResNet10,\n",
    "                ResNet18 = ResNetFeat.ResNet18,\n",
    "                ResNet34 = ResNetFeat.ResNet34,\n",
    "                ResNet50 = ResNetFeat.ResNet50,\n",
    "                ResNet101 = ResNetFeat.ResNet101)\n",
    "    return model_dict[model_name](num_classes, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(model,data_loader):\n",
    "    \n",
    "    feature_set=[]\n",
    "    label_set=[]\n",
    "    for i, (x,y) in enumerate(data_loader):\n",
    "        \n",
    "        \n",
    "        # ignoriang the data that belong to base class\n",
    "        index=0\n",
    "        while True:\n",
    "            if(y[index] not in novel_classes):\n",
    "                y=torch.cat([y[0:index], y[index+1:]])\n",
    "                x=torch.cat([x[0:index], x[index+1:]])\n",
    "                index-=1\n",
    "            index+=1\n",
    "\n",
    "            if(len(y)==index):\n",
    "                break\n",
    "\n",
    "        if(len(y)==0):\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        if i%10 == 0:\n",
    "            print('{:d}/{:d}'.format(i, len(data_loader)))\n",
    "        x = x.cuda()\n",
    "        x_var = Variable(x)\n",
    "        \n",
    "        scores, feats = model(x_var)\n",
    "        feature_set.extend(feats.data.cpu().numpy())\n",
    "        label_set.extend(y.cpu().numpy())\n",
    "        \n",
    "    return (np.array(feature_set),np.array(label_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    with open(cfg,'r') as f:\n",
    "        data_params = yaml.load(f)\n",
    "\n",
    "    data_loader = data.get_data_loader(data_params)\n",
    "    model = get_model(model, num_classes)\n",
    "    model = model.cuda()\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    tmp = torch.load(modelfile)\n",
    "    if ('module.classifier.bias' not in model.state_dict().keys()) and ('module.classifier.bias' in tmp['state'].keys()):\n",
    "        tmp['state'].pop('module.classifier.bias')\n",
    "    \n",
    "    model.load_state_dict(tmp['state'])\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set,label_set=get_features(model,data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-95-15b8ca0374ca>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-95-15b8ca0374ca>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    (x,y) = torch.tensor(features[idx],dtype='float32'),torch.tensor(labels[idx],dtype'float32)\u001b[0m\n\u001b[0m                                                                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "def training_loop(features,labels, num_classes, lr, momentum, wd, batchsize=1000, maxiters=1000):\n",
    "    featdim = features.shape[1]\n",
    "    model = nn.Linear(featdim, num_classes)\n",
    "    model = model.cuda()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr, momentum=momentum, dampening=momentum, weight_decay=wd)\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    loss_function = loss_function.cuda()\n",
    "    \n",
    "    for i in range(maxiters):\n",
    "        idx=i%len(labels)\n",
    "        (x,y) = torch.tensor(features[idx],dtype='float32'),torch.tensor(labels[idx],dtype'float32)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = Variable(x.cuda())\n",
    "        y = Variable(y.cuda())\n",
    "        scores = model(x)\n",
    "\n",
    "        loss = loss_function(scores,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i%100==0):\n",
    "            print('{:d}: {:f}'.format(i, loss.data[0]))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not infer dtype of numpy.int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-eb501a9e1460>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-93-b13a5beb5e57>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(features, labels, num_classes, lr, momentum, wd, batchsize, maxiters)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not infer dtype of numpy.int64"
     ]
    }
   ],
   "source": [
    "model = training_loop(feature_set,label_set, num_classes, lr, momentum, wd, batch_size, maxiters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_loop(model,test_loader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
